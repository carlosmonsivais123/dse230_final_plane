{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Process in GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to run this process end to end we have to run it in GCP using DataProc to spin up clusters and run our PySpark code there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To run the process, just run the cell below which will run the main.py file kicking off the other Python files that have dependencies on this file.\n",
    "### The logs of the process will be shown below. More information on the files can be read in the README.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCP Platform Output Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is an image showing the buckets where the DataProc PySpark process output our data.\n",
    "1. DataProc_Files: These are the Pyspark files in the DataPorc_Files folder that are uploaded to this bucket to be used when running PySpark in GCP.\n",
    "2. EDA_Static_Images: These are the EDA images that are output as part of the process once the sub files are created using PySpark.\n",
    "3. Spark_Data_Output: These are output files that are created in PySpark based on our data such as the summary statistics, proportion conts, etc.\n",
    "4. Spark_Models: These are the models that we created in PySpark and are saved in this directory to load and use later.\n",
    "5. flight-delays: This is the actual data including the airlines.csv, airports.csv, and flights.csv\n",
    "6. requirements.txt: This is the requirements file that can be used to have the same libary versions that we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='gcp_platform.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "948b3ef3c7f3779da0fb6aa870fa66a0cb8fafc1112b0f4c52e6a358a38e2d8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pyspark_230_env')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}